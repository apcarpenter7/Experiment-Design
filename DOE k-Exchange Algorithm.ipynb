{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook covers the k-Exhange Algorithm for D-optimal experimental designs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal experimental designs allow for fewer experiemntal runs compared to traditional factorial designs. One popular type of optimal design is D-optimal, which seeks to maximize the determinant of the information matrix $X^TX$, where $X$ is a subset of the full factorial design matrix of possible experimental runs. This is also equivalent to minimizing the determinant of the dispersion matrix $(X^TX)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_disp_matrix(design_matrix):\n",
    "    return np.linalg.inv(design_matrix.T @ design_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explore choosing a D-optimal design with 3 variables each containing 3 levels (-1, 0, 1) with full interactions between the variables plus an intercept. The model would take the form\n",
    "$$x_1 + x_2 + x_3 + x_1^2 + x_ 1x_2 + x_1 x_3 + x_2^2 + x_2 x_3 + x_3^2 + \\beta$$\n",
    " The full matrix is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1. -1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1.  0.  1.  1. -0.  1. -0.  0.  1.]\n",
      " [-1. -1.  1.  1.  1. -1.  1. -1.  1.  1.]\n",
      " [-1.  0. -1.  1. -0.  1.  0. -0.  1.  1.]\n",
      " [-1.  0.  0.  1. -0. -0.  0.  0.  0.  1.]\n",
      " [-1.  0.  1.  1. -0. -1.  0.  0.  1.  1.]\n",
      " [-1.  1. -1.  1. -1.  1.  1. -1.  1.  1.]\n",
      " [-1.  1.  0.  1. -1. -0.  1.  0.  0.  1.]\n",
      " [-1.  1.  1.  1. -1. -1.  1.  1.  1.  1.]\n",
      " [ 0. -1. -1.  0. -0. -0.  1.  1.  1.  1.]\n",
      " [ 0. -1.  0.  0. -0.  0.  1. -0.  0.  1.]\n",
      " [ 0. -1.  1.  0. -0.  0.  1. -1.  1.  1.]\n",
      " [ 0.  0. -1.  0.  0. -0.  0. -0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  1. -1.  0.  0. -0.  1. -1.  1.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  0.  0.  1.]\n",
      " [ 0.  1.  1.  0.  0.  0.  1.  1.  1.  1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1.  1.  1.  1.]\n",
      " [ 1. -1.  0.  1. -1.  0.  1. -0.  0.  1.]\n",
      " [ 1. -1.  1.  1. -1.  1.  1. -1.  1.  1.]\n",
      " [ 1.  0. -1.  1.  0. -1.  0. -0.  1.  1.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  1.  1.  0.  1.  0.  0.  1.  1.]\n",
      " [ 1.  1. -1.  1.  1. -1.  1. -1.  1.  1.]\n",
      " [ 1.  1.  0.  1.  1.  0.  1.  0.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n",
      "Number of experiments in full factorial run = 27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('3_fact_full_inter.csv').values\n",
    "print(df)\n",
    "print(f'Number of experiments in full factorial run = {df.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full factorial run of 3 variables with 3 levels would require 27 runs. Let's say we only had the money to complete 15 total runs. Choosing 15 runs out of 27 would give us a possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of possible combinations = 17383860!\n"
     ]
    }
   ],
   "source": [
    "from math import comb\n",
    "print(f'Total number of possible combinations = {comb(27, 15)}!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is over 17 million possible combinations! Additionally, we must compute the determinant of each one of these possibilities. Numpy uses LU decomposition to compute the determinant with a run time of $O(n)^3$. Computationally it becomes impractical to enumerate all possible runs and compute the determinant. This is especially true when the number of experimental factors increases. Let's look at the number of possible experiemnts and time complexity if there were 5 varibles with 3 levels and we could only run 20 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 total runs for a full factorial experiment\n",
      "94833792242740173136768780680 total possible ways to pick 20 runs!\n",
      "758670337941921385094150245440000 total run time!\n"
     ]
    }
   ],
   "source": [
    "print(f'{3 ** 5} total runs for a full factorial experiment')\n",
    "print(f'{comb(3 ** 5, 20)} total possible ways to pick 20 runs!')\n",
    "print(f'{comb(3 ** 5, 20) * (20 ** 3)} total run time!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exchange algorithms start with randomly selecting a potential design matrix. The remaining design points are then sequentially swapped into the candidate design matrix and their effect on the determinant is calculated. If it increases, these experimental runs are swapped out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first start out by calculating the variance of a single experimental run $\\chi_x$. Note that we are defining $\\chi_x$ as a $\\textit{column}$ vector.\n",
    "<br>\n",
    "<br>\n",
    "$$d(\\chi_x) = \\chi^{T}_x * (X^{T}_nX_n)^{-1} * \\chi_x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_single_point(design_point, dispersion_matrix):\n",
    "    \n",
    "    #Reshape for proper calc\n",
    "    design_point = design_point.reshape((-1, 1))\n",
    "    \n",
    "    return (design_point.T @ dispersion_matrix @ design_point)[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we want to see what impact adding and deleting points from the candidate design matrix has on the determinant. Adding experimental run $\\chi_j$ increases the determinant proportionally by its variance $d(\\chi_j)$\n",
    "<br>\n",
    "<br>\n",
    "$$|X_{new}^T X_{new}| = |X_{old}^T X_{old}| * (1 + d(\\chi_j))$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice property because we do not have to compute the determinant each time. With the k-Exchange algorithm, we are swapping point $\\chi_i$ in the candidate design matrix and potential run $\\chi_j$. Similar to the equation above, we can see the impact of this swap on the determinant by \n",
    "<br>\n",
    "<br>\n",
    "$$ |X_{new}^T X_{new}| = |X_{old}^T X_{old}| * (1 + \\Delta (\\chi_i, \\chi_j)) $$\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\Delta (\\chi_i, \\chi_j))$ uses the combined varaince of $\\chi_i$ and $\\chi_j$\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d(\\chi_i, \\chi_j) = \\chi^{T}_i * (X^{T}_nX_n)^{-1} * \\chi_j  = \\chi^{T}_j * (X^{'}_nX_n)^{-1} * \\chi_i $$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Delta(\\chi_i, \\chi_j) = d(\\chi_j) - [d(\\chi_i)d(\\chi_j) - (d(\\chi_i, \\chi_j))^2] - d(\\chi_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_combined(point_i, point_j, dispersion_matrix):\n",
    "\n",
    "    point_i = point_i.reshape((-1, 1))\n",
    "    point_j = point_j.reshape((-1, 1))\n",
    "    \n",
    "    return (point_i.T @ dispersion_matrix @ point_j)[0][0]\n",
    "\n",
    "\n",
    "def delta(d_i, d_j, d_comb):\n",
    "\n",
    "    return d_j - (d_i * d_j - d_comb ** 2) - d_i\n",
    "\n",
    "\n",
    "def update_det(current_det, delta_ij):\n",
    "\n",
    "    return current_det * (1 + delta_ij)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the k-Exchange algorithm, we start by randomly selecting a design matrix. Next, we look to exchange the $k$ points with the lowest variance of prediction. $k$ is suggested to be selected as $k \\leq \\frac{n}{4}$ with $n$ being the number of desired experimental runs. The pseudo-code follows as "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a random design <br>\n",
    "While pairs of points $(\\chi_i, \\chi_j)$ with positive $\\Delta(\\chi_i, \\chi_j)$ exist <br>\n",
    "$\\;\\;\\;\\;$ Calculate $d(\\chi_i)$ for all design points <br>\n",
    "$\\;\\;\\;\\;$ Find the $k$ design points witht the lowest prediction variance <br>\n",
    "$\\;\\;\\;\\;$ For design point $\\chi_1$ to $\\chi_k$ <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ Calculate the variance of predicition $d(\\chi_i)$ <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;$ For support point $\\chi_1$ to $\\chi_N$ <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Calculate the variance of prediction $d(\\chi_j)$ for this support point<br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Calculate the combined variance of prediction $d(\\chi_i, \\chi_j)$ for this pair<br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Calculate the delta function $\\Delta(\\chi_i, \\chi_j)$ for this pair<br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Select pair with the maximum $\\Delta$ <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ If max delta > 0 then <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ If two pairs have same max $\\Delta$ <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$  Select pair randomly <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Exchange point $\\chi_i$ with $\\chi_j$ <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Update information and disperion matrix <br>\n",
    "$\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;$ Reset max delta <br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before coding this out, we'll define some helper functions to make this a little cleaner. <br><br> First we'll define a function for generating a random design matrix from a full factorial design matrix. We'll return a design matrix and its indicies from the full factorial matrix, and the left over \"support points\" and support indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_design(full_matrix, n_runs):\n",
    "    \n",
    "    #Get random indicies for design matrix\n",
    "    r, c = full_matrix.shape\n",
    "    rand_ind = np.random.choice(np.arange(r), size = n_runs, replace = False)\n",
    "    \n",
    "    #Indicies for design and support points\n",
    "    design_mask = ~np.ones(r, bool)\n",
    "    design_mask[rand_ind] = True\n",
    "    design_ind = np.arange(0, r)[design_mask]\n",
    "    support_ind = np.arange(0, r)[~design_mask]\n",
    "    \n",
    "    #Get support points\n",
    "    support_points = full_matrix[support_ind, :]\n",
    "    \n",
    "    #Get the design matrix\n",
    "    design_mat = full_matrix[design_ind, :]\n",
    "   \n",
    "    return design_mat, design_ind, support_points, support_ind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll calculate the design variances for all points. We'll define a function for calculating the disperion matrix $(X^T X)^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_disp_matrix(design_matrix):\n",
    "    \n",
    "    return np.linalg.inv(design_matrix.T @ design_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, instead of looping through and calculating $d(\\chi_x) = \\chi^{T}_x * (X^{T}_nX_n)^{-1} * \\chi_x $ for each $\\chi_x$, we can do this in one shot by computing <br>\n",
    " $$diag(X^T * (X^{T}_nX_n)^{-1} * X)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_variances(design_matrix, dispersion_mat):\n",
    "\n",
    "    return np.diag(design_matrix @ dispersion_mat @ design_matrix.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define a function for finding the k lowest variances of the design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_lowest_var_ind(variances, k):\n",
    "\n",
    "    return np.sort(np.argsort(variances)[:k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to put it all together! One important thing to note is that this alogrithm and other coordinate exchange algorithms are not guaranteed to find the *exact* optimal design. The output of these alogrithms greatly depends on the randomly chosen design matrix at the beginning of the alorgithm. For this reason, we'll specifiy the number of times to run the k-Exchange alorgithm in our function to potentially find better designs. We'll also define the maximum number of iterations to look for potential points to swap out in the algorthim to speed things up if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_exchange(full_factorial_matrix, desired_num_experiments, num_runs, seed, maximum_iterations):\n",
    "\n",
    "    #Define k \n",
    "    k = round(desired_num_experiments / 4)\n",
    "\n",
    "    #Keep track of all determinants and indicies to find the best run\n",
    "    d = {}\n",
    "    \n",
    "    #Number of times to run the algorithm\n",
    "    for run in range(num_runs):\n",
    "\n",
    "        #Chnage seed each run to get different output for each run\n",
    "        np.random.seed(seed + run)\n",
    "\n",
    "        #Generate random design\n",
    "        X, X_ind, support_points, support_ind = random_design(full_factorial_matrix, desired_num_experiments)\n",
    "\n",
    "        #It is possible the randomly generated design has orthogonal columns making the determinant zero. In this case, we'll skip this iteration\n",
    "        if np.linalg.det(X.T @ X) == 0:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "\n",
    "            #Calculate dispersion matrix\n",
    "            X_disp = calc_disp_matrix(X)\n",
    "\n",
    "            #Whilte couples with positive delta are found\n",
    "            max_delta = 1\n",
    "            max_iters = 0\n",
    "\n",
    "            while max_delta > 0 and max_iters < maximum_iterations:\n",
    "\n",
    "                maximum_deltas = []\n",
    "                #Calculate the vriance of prediction d(x_i) for all design points\n",
    "                dv = design_variances(X, X_disp)\n",
    "\n",
    "                #Select k design points with the lowest variance\n",
    "                k_ind = k_lowest_var_ind(dv, k)\n",
    "                k_design_points = X[k_ind]\n",
    "\n",
    "                #For design point x_1 to x_k do\n",
    "                for i in range(k):\n",
    "\n",
    "                    #Calculate the varaince of prediction d(x_i) for this point\n",
    "                    x_i = k_design_points[0, :]\n",
    "                    dx_i = variance_single_point(x_i, X_disp)\n",
    "\n",
    "                    #For support point x_1 to x_N do\n",
    "                    couple_deltas = []\n",
    "                    for j in range(len(support_ind)):\n",
    "\n",
    "                        #Calculate the variance of prediction for this support point\n",
    "                        x_j = support_points[j, :]\n",
    "                        dx_j = variance_single_point(x_j, X_disp)\n",
    "\n",
    "                        #Calculate the variance of prediction for this couple\n",
    "                        dx_ij_comb = variance_combined(x_i, x_j, X_disp)\n",
    "\n",
    "                        #Calculate the delta function for this couple\n",
    "                        x_ij_delta = delta(dx_i, dx_j, dx_ij_comb)\n",
    "                        couple_deltas.append(x_ij_delta)\n",
    "\n",
    "                    #Select couple with max delta\n",
    "                    delta_i = couple_deltas[np.argmax(couple_deltas)]\n",
    "\n",
    "                    #If max delta positive exchange point x_i and x_j\n",
    "                    if delta_i > 0:\n",
    "                        ind_j = np.argmax(couple_deltas)\n",
    "                        support_exchange = support_ind[ind_j]\n",
    "                        design_exchange = X_ind[k_ind[i]]\n",
    "                        support_ind[ind_j] = design_exchange\n",
    "                        X_ind[np.where(X_ind == design_exchange)[0][0]] = support_exchange\n",
    "\n",
    "                        #Update information matrix\n",
    "                        X = full_factorial_matrix[X_ind]\n",
    "\n",
    "                        #Case for if calculating the dispersion matrix produces a singular matrix\n",
    "                        try:\n",
    "                            X_disp = calc_disp_matrix(X)\n",
    "                        except:\n",
    "                            continue\n",
    "                        \n",
    "                    maximum_deltas.append(delta_i)\n",
    "                max_delta = np.max(maximum_deltas)\n",
    "                max_iters += 1\n",
    "\n",
    "        d[int(np.linalg.det(X.T @ X))] = X_ind\n",
    "\n",
    "    return full_factorial_matrix[[v for k, v in sorted(d.items(), key = lambda x: x[0], reverse = True)][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our optimal design!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Design is\n",
      "[[-1. -1.  1.  1.  1. -1.  1. -1.  1.  1.]\n",
      " [-1.  0. -1.  1. -0.  1.  0. -0.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1. -1.  1. -1.  1.  1. -1.  1.  1.]\n",
      " [ 1. -1.  1.  1. -1.  1.  1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1. -1.  1.  1.  1.  1.]\n",
      " [ 0. -1. -1.  0. -0. -0.  1.  1.  1.  1.]\n",
      " [-1. -1.  0.  1.  1. -0.  1. -0.  0.  1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1.  1.  1.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  1. -1.  0.  0. -0.  1. -1.  1.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  1. -1.  1.  1. -1.  1. -1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "X = k_exchange(df, 15, 1000, 44, 1000)\n",
    "print('Optimal Design is')\n",
    "print(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ac6ff8f9016400d7cb78f3687104c58a77bf0b74a31ad08136384743c96fa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
